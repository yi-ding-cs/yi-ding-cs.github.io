<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Welcom to Ding Yi's Homepage</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Ding Yi (丁一）</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://dyi1994.github.io/"><img src="myphoto.png" alt="alt text" width="180px" /></a>&nbsp;</td>
<td align="left"><p>Ph.D., MSc, B.Eng<br />
Research Assistant Professor<br />
College of Computing & Data Science<br />
Nanyang Technological University,<br />
Singapore<br /> 
Member, IEEE (CIS and EMBS) and PREMIA <br />
Email: yi006@e.ntu.edu.sg/ding.yi@ntu.edu.sg <br />
<br />
<a href="https://www.researchgate.net/profile/Yi-Ding-113">[ResearchGate]</a> <a href="https://scholar.google.com/citations?user=8SYAgGIAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/yi-ding-cs">[GitHub]</a></p>
</td></tr></table>
<h2>Biography</h2>
<p> I am currently a Research Assitant Professor at College of Computing and Data Science, Nanyang Technological University (NTU), Singapore. I received my Ph.D. from the School of Computer Science and Engineering (SCSE) at Nanyang Technological University, Singapore in 2023, supervised by <a href="https://ntu-cbcr.org/">Prof Guan Cuntai</a>. 
Before that, I received my MSc from the School of Electrical and Electronics Engineering (EEE) at Nanyang Technological University, Singapore in 2018, supervised by <a href="https://dr.ntu.edu.sg/cris/rp/rp00292"> Prof Chen Tupei</a>. 
Previously, I earned my B.Eng degree from the School of Information Science and Technology at Donghua University, Shanghai, China in 2017.
<br /><br />
My research interests include brain-computer interface, deep/machine learning, graph neural networks, affective computing, computational neuroscience, multimodal emotion recognition,
and their applications in neural signal decoding and mental disorder regulation. </p>
<h2>News</h2>
<table class="imgtable"><tr><td>
<ul>
<li><p>[24-Dec-2024] I was awarded as a <i><b> Research Assistant Professor </b></i> in NTU, thanks to my supervisor Prof Guan</b></i></p>
</li>
<li><p>[21-Dec-2024] 2 papers were accepted by <i><b>ICASSP-25</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[16-Dec-2024] 1 paper was accepted by <i><b>IEEE Transactions on Image Processing (TIP)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[16-Nov-2024] 2 papers were accepted by <i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[12-Nov-2024] 1 paper was accepted by <i><b>IEEE Transactions on Affective Computing (TAFFC)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[17-June-2024] 1 paper was accepted by <i><b>Neural Networks (NN)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[8-May-2024] 1 paper was accepted by <i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[16-Apr-2024] 1 paper was accepted by <i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[4-Jan-2024] 1 paper was accepted by <i><b>Neural Networks (NN)</b></i>, thanks all co-authors</b></i></p>
</li>
<li><p>[31-Aug-2023] LGGNet was honored with <i><b>the PREMIA Best Student Paper Awards Honourable Mention 2023</b></i></p>
</li>
<li><p>[12-Apr-2023] 2 papers were accepted by <i><b>EMBC-23</b></i></p>
</li>
<li><p>[11-Jan-2023] 1 paper was accepted by <i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</b></i></p>
</li>
<li><p>[25-Nov-2022] 1 PCT patent application (PCT/SG2022/050243), "Mental Arousal Level Regulation System and Method", was pubilished</p>
</li>
<li><p>[19-Aug-2022] My Ph.D. Thesis, "Neurophysiology-Inspired Neural Networks for Affective Brain-Computer Interfaces", was submitted and endorsed by Prof Guan</p>
</li>
<li><p>[26-Apr-2022] 1 was accepted by <i><b>IJCNN-22</b></i></p>
</li>
<li><p>[16-Apr-2022] 1 was accepted by <i><b>IEEE Transactions on Affective Computing (TAFFC)</b></i></p>
</li>
<li><p>[15-Apr-2022] 1 was accepted by <i><b>CVPRW-22</b></i></p>
</li>
<li><p>[15-Apr-2022] Our team achieved the runner-up in the Valence-arousal estimation challenge of ABAW Competition held in <i><b>CVPR-22</b></i></p>
</ul>
</td></tr></table>
<h2>Publications</h2>
  <h3>Journal Papers</h3>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10763464">EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces</a><br />
<b>Yi Ding</b>, Yong Li, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu, Xinliang Zhou, and Cuntai Guan<br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024 </b></i>[JCR Q1, IF=6.7]<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10763464">[PDF]</a><a href="https://github.com/yi-ding-cs/EEG-Deformer">[code]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10758636">REI-Net: A Reference Electrode Standardization Interpolation Technique based 3D CNN for Motor Imagery Classification</a><br />
Meiyan Xu, Jie Jiao, Duo Chen, <b>Yi Ding</b>, et. al. <br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024. </b></i>[JCR Q1, IF=6.7]</p>
</li>
</ul>

<ul>
<li><p>Decoupled Doubly Contrastive Learning for Cross Domain Facial Action Unit Detection<br />
Li, Y., Liu, M., Cui, Z., <b>Ding, Y.</b>, Zong, Y., Zheng, W., Shan, S., Guan, C. <br />
<i><b>IEEE Transactions on Image Processing (TIP), 2024. (accepted) </b></i>[JCR Q1, IF=10.8]</p>
</li>
</ul>

<ul>
<li><p>Beyond Overfitting: Doubly Adaptive Dropout for Generalizable AU Detection<br />
Li, Y., Ren, Y., Niu, X., Wei, X., <b>Ding, Y.</b>, Guan, C. <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), 2024. (accepted) </b></i>[JCR Q1, IF=9.6]</p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024003940?via%3Dihub">Leveraging Temporal Dependency for Cross-subject-MI BCIs by Contrastive Learning and Self-attention</a><br />
Hao Sun, <b>Yi Ding</b>, Jianzhu Bao, Chengxuan Tong, Jing Jin, Cuntai Guan <br />
<i><b>Neural Networks (NN), 2024. </b></i>[JCR Q1, IF=7.8]</p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10528328">TASA: Temporal Attention with Spatial Autoencoder Network for Odor-induced Emotion Classification Using EEG</a> <br />
Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, Zhuo Zhang, Haihong Zhang, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE), 2024. </b></i>[JCR Q1, IF=4.9]</p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10506986">MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition</a> <br />
<b>Yi Ding</b>*, Su Zhang*, Chuangao Tang, Cuntai Guan <br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024. </b></i>[JCR Q1, IF=7.7] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10506986">[PDF]</a><a href="https://github.com/yi-ding-cs/MASA-TCN">[code]</a> *: equal contribution</p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2308.11636"> Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning</a> <br />
Rui Liu, Yuanyuan Chen, Anran Li, <b>Yi Ding </b>, Han Yu, Cuntai Guan <br />
<i><b> Neural Networks(NN), 2024. </b></i>[JCR Q1, IF=7.8]<a href="https://arxiv.org/pdf/2308.11636.pdf">[PDF]</a></p>
</li>
</ul>
  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10025569">LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Chengxuan Tong, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023. </b></i>[JCR Q1, IF=10.4] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10025569">[PDF]</a><a href="https://github.com/yi-ding-cs/LGG">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9762054">TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition
</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Su Zhang, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), 2022.</i></b>  [JCR Q1, IF=11.2, Highly cited (WoS-2024-May)] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9762054">[PDF]</a><a href="https://github.com/yi-ding-cs/TSception">[code]</a></p>
</li>
</ul>

<h3>Conference Papers</h3>
  
<ul>
<li><p> <a href="https://ieeexplore.ieee.org/abstract/document/10340644">GIGN: Learning Graph-in-graph Representations of EEG Signals for Continuous Emotion Recognition </a> <br />
<b>Yi Ding</b>, and Cuntai Guan <br />
<i><b>45rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2023.</b></i> <a href="https://arinex.com.au/EMBC/pdf/full-paper_45.pdf">[PDF] </a><a href="https://github.com/yi-ding-cs/GIGN">[code] </a> </p>
</li>
</ul>
  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10340760">MTDN: Learning Multiple Temporal Dynamics Representation for Emotional Valence Classification with EEG </a><br />
Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, and Cuntai Guan <br />
<i><b>45rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2023. </b></i> <a href="https://arinex.com.au/EMBC/pdf/full-paper_232.pdf">[PDF] </a></p>
</li>
</ul>
 
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9892920"> TESANet: Self-attention network for olfactory EEG classification </a><br />
  Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, Zhuo Zhang, Haihong Zhang, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2022. </b></i> </p>
</li>
</ul>

<ul>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/html/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.html">Continuous Emotion Recognition Using Visual-Audio-Linguistic Information: A Technical Report for ABAW3</a> <br />
Su Zhang, Ruyi An, <b>Yi Ding</b>, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. </b></i> <a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW3">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9629575"> Learning Generalized Representations of EEG between Multiple Cognitive Attention Tasks</a> <br />
<b>Yi Ding*</b>, Nigel Wei Jun Ang*, Aung Aung Phyo Wai, Cuntai Guan <br />
<i><b>43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2021. </b></i> <a href="https://paperhost.org/proceedings/embs/EMBC21/files/0591.pdf">[PDF]</a>*: equal contribution</p>
</li>
</ul>
<ul>
<li><p><a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/html/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.html">Continuous Emotion Recognition With Audio-Visual Leader-Follower Attentive Fusion</a> <br />
Su Zhang*, <b>Yi Ding*</b>, Ziquan Wei*, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2021. </b></i> <a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW2">[code]</a> *: equal contribution</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9206750">TSception:A Deep Learning Framework for Emotion Detection Using EEG</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Qiuhao Zeng, Duo Chen, Aung Aung Phyo Wai, Tih-Shih Lee, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2020. </b></i> <a href="https://arxiv.org/pdf/2004.02965.pdf"> [PDF]</a><a href="https://github.com/deepBrains/TSception">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/8717063">Motor-Controlled Spindle (MCS) Detection for Primate in BCI System</a> <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br />
  <i><b>International IEEE/EMBS Conference on Neural Engineering (NER), 2019. </b></i></p>
</li>
</ul>
<ul>
<li><p>Intracortical Activity decoding of motor imagery based on Deep Convolutional Neural Network: a Pilot Study. <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br />
  <i><b>GBCIC, 2019. </b></i></p>
</li>
</ul>
<h2>Patents</h2>
<ul>
<li>
Mental Arousal Level Regulation System and Method (PCT/SG2022/050243 & 202280034110.2)
</li>
</ul>

<ul>
<li>
Music-based Emotion Profiling System. (PCT/SG2023/050757)
</li>
</ul>
  
<ul>
<li>
System and Method for Cognitive Enhancement Based on Electroencephalogram(EEG) Signals. (PCT/SG2023/050758)
</li>
</ul>
  
<h2>Projects</h2>
<ul>
<li>
Study Mental State Detection from Brain-Computer Interface System with EEG
</li>
</ul>
  
<ul>
<li>
Brain-Computer Interface-based Emotion Regulation for General Anxiety
</li>
</ul>
  
<ul>
<li>
NOURISH: Next-Generation Brain-Computer-Brain Platform – A Holistic Solution for the Restoration & Enhancement of Brain Functions
</li>
</ul>

<ul>
<li>
Attention-driven Car Racing Game with a Deep Learning Engine
</li>
</ul>
  
<h2>Acadamic service</h2>
  
<ul>
<li>
IEEE Transactions on Neural Networks and Learning Systems, reviewer
</li>
</ul>

<ul>
<li>
IEEE Internet of Things Journal, reviewer
</li>
</ul>

<ul>
<li>
IEEE Journal of Biomedical and Health Informatics, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Signal Processing, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Neural Systems and Rehabilitation Engineering, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Cognitive and Developmental Systems, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Artificial Intelligence, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Human-Machine Systems, reviewer
</li>
</ul>

<ul>
<li>
Pattern Recognition, reviewer
</li>
</ul>

<ul>
<li>
Applied Soft Computing, reviewer
</li>
</ul>

<ul>
<li>
International Journal of Human-Computer Interaction, reviewer
</li>
</ul>

<ul>
<li>
Neurocomputing, reviewer
</li>
</ul>

<ul>
<li>
Cognitive Neurodynamics, reviewer
</li>
</ul>

<ul>
<li>
Neural Processing Letters, reviewer
</li>
</ul>
  
<ul>
<li>
Applied Artificial Intelligence, reviewer
</li>
</ul>

<ul>
<li>
Brain Research Bulletin, reviewer
</li>
</ul>

<ul>
<li>
ICASSP-25, IJCNN-25, reviewer
</li>
</ul>


<ul>
<li>
Brain-X, Young editorial board
</li>
</ul>

<h2>Teaching</h2>
<ul>
<li>
Mr. Ruyi An (NTU URECA 2021-2023, and FYP 2023-2024)
</li>
</ul>

<ul>
<li>
Mr. Lee Joonhei (NTU FYP 2023-2024)
</li>
</ul>

<ul>
<li>
Mr. Jethro Phuah An Ping (NTU FYP 2022-2023)
</li>
</ul>

<ul>
<li>
Mr. Kong Hou Jing (NTU FYP 2021-2022)
</li>
</ul>
  
<ul>
<li>
Miss. Gan Kah Ee (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Miss. Yuhan Zhang (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Mr. Nigel Wei Jun Ang (NTU FYP 2020-2021)
</li>
</ul>

</div>
</body>
</html>
