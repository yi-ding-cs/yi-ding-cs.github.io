<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Welcom to Ding Yi's Homepage</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Ding Yi (丁一）</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://dyi1994.github.io/"><img src="photo.JPG" alt="alt text" width="180px" /></a>&nbsp;</td>
<td align="left"><p>Ph.D. Candidate, MSc <br />
Research Associate, Student Member IEEE<br />
School of Computer Science and Engineering <br />
Nanyang Technological University, <br />
Singapore <br /> 
Email: yi006@e.ntu.edu.sg <br />
<br />
<a href="https://www.researchgate.net/profile/Yi-Ding-113">[ResearchGate]</a> <a href="https://scholar.google.com/citations?user=8SYAgGIAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/yi-ding-cs">[GitHub]</a></p>
</td></tr></table>
<h2>Biography</h2>
<p>I am currently a fourth-year Ph.D. student and Reseach Associate in the School of Computer Science and Engineering (SCSE), Nanyang Technological University, Singapore, supervised by <a href="https://personal.ntu.edu.sg/ctguan/">Prof Guan Cuntai</a>. 
Before that, I received my MSc in the School of Electrical and Electronics Engineering (EEE), Nanyang Technological University, Singapore in 2018, supervised by <a href="https://dr.ntu.edu.sg/cris/rp/rp00292"> Prof Chen Tupei</a>. 
Previously, I received my B.Eng degree from School of Information Science and Technology, Donghua University, Shanghai, China in 2017. <br /><br />
My research interests include brain-computer interface, deep/machine learning, graph neural networks, affective computing, computational neuroscience, 
and their applications in neural signal decoding and mental disorder regulation. I recently work on discrete and continuous emotion recognition using EEG, visual, and audio signals.</p>
<h2>News</h2>
<table class="imgtable"><tr><td>
<ul>
<li><p>[11-Jan-2023] One paper was accepted by <i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</b></i></p>
</li>
<li><p>[25-Nov-2022] One PCT patent (PCT/SG2022/050243), "Mental Arousal Level Regulation System and Method", was pubilished</p>
</li>
<li><p>[19-Aug-2022] My Ph.D. Thesis, "Deep Learning in Affective Brain-Computer Interface", was submitted and endorsed by Prof Guan</p>
</li>
<li><p>[26-Apr-2022] One paper was accepted by <i><b>IJCNN-22</b></i></p>
</li>
<li><p>[16-Apr-2022] One paper was accepted by <i><b>IEEE Transactions on Affective Computing</b></i></p>
</li>
<li><p>[15-Apr-2022] One paper was accepted by <i><b>CVPRW-22</b></i></p>
</li>
<li><p>[15-Apr-2022] Our team achieved the runner-up in the Valence-arousal estimation challenge of ABAW Competition held in <i><b>CVPR-22</b></i></p>
</ul>
</td></tr></table>
<h2>Publications</h2>
  <h3>Journal Papers</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2105.02786">LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Chengxuan Tong, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023. </b></i>[JCR Q1, IF=14.25] <a href="https://arxiv.org/pdf/2105.02786.pdf">[PDF]</a><a href="https://github.com/yi-ding-cs/LGG">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2104.02935">TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition
</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Su Zhang, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), 2022.</i></b>  [JCR Q1, IF=13.99] <a href="https://arxiv.org/pdf/2104.02935.pdf">[PDF]</a><a href="https://github.com/yi-ding-cs/TSception">[code]</a></p>
</li>
</ul>

<ul>
<li><p>MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition <br />
<b>Yi Ding</b>*, Su Zhang*, Chuangao Tang, Cuntai Guan <br />
<i><b>Pattern Recognition (PR), under review. </b></i>[JCR Q1, IF=8.518] *: equal contribution</p>
</li>
</ul>
  
<ul>
<li><p>Leader-follower Attentive Network for Continuous Emotion Recognition <br />
Su Zhang*, <b>Yi Ding</b>*, Chuangao Tang, Cuntai Guan <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), under revision. </b></i>[JCR Q1, IF=13.99] *: equal contribution</p>
</li>
</ul>

<ul>
<li><p>STECO: Self-supervised Temporal Correlation Learner for Emotion Recognition from EEG <br />
Ruyi An*, <b>Yi Ding</b>*, Ziyuan Zhao, Cuntai Guan <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), under revision. </b></i>[JCR Q1, IF=13.99] *: equal contribution</p>
</li>
</ul>

<h3>Conference Papers</h3>
<ul>
<li><p> TESANet: Self-attention network for olfactory EEG classification <br />
  Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, Zhuo Zhang, Haihong Zhang, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2022. </b></i> </p>
</li>
</ul>

<ul>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/html/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.html">Continuous Emotion Recognition Using Visual-Audio-Linguistic Information: A Technical Report for ABAW3</a> <br />
Su Zhang, Ruyi An, <b>Yi Ding</b>, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. </b></i> <a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW3">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9629575"> Learning Generalized Representations of EEG between Multiple Cognitive Attention Tasks</a> <br />
<b>Yi Ding*</b>, Nigel Wei Jun Ang*, Aung Aung Phyo Wai, Cuntai Guan <br />
<i><b>43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2021. </b></i> <a href="https://paperhost.org/proceedings/embs/EMBC21/files/0591.pdf">[PDF]</a>*: equal contribution</p>
</li>
</ul>
<ul>
<li><p><a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/html/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.html">Continuous Emotion Recognition With Audio-Visual Leader-Follower Attentive Fusion</a> <br />
Su Zhang*, <b>Yi Ding*</b>, Ziquan Wei*, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2021. </b></i> <a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW2">[code]</a> *: equal contribution</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9206750">TSception:A Deep Learning Framework for Emotion Detection Using EEG</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Qiuhao Zeng, Duo Chen, Aung Aung Phyo Wai, Tih-Shih Lee, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2020. </b></i> <a href="https://arxiv.org/pdf/2004.02965.pdf"> [PDF]</a><a href="https://github.com/deepBrains/TSception">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/8717063">Motor-Controlled Spindle (MCS) Detection for Primate in BCI System</a> <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br />
  <i><b>International IEEE/EMBS Conference on Neural Engineering (NER), 2019. </b></i></p>
</li>
</ul>
<ul>
<li><p>Intracortical Activity decoding of motor imagery based on Deep Convolutional Neural Network: a Pilot Study. <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br />
  <i><b>GBCIC, 2019. </b></i></p>
</li>
</ul>
<h2>Patents</h2>
<ul>
<li>
Mental Arousal Level Regulation System and Method (PCT/SG2022/050243)
</li>
</ul>
  
<ul>
<li>
Closed-loop Virtual Reality Exposure Therapy for Social Anxiety Disorder based on Arousal Detection from BCI. (Technology Disclosure)
</li>
</ul>

<ul>
<li>
A Novel Music-based Emotion Profiling System. (Technology Disclosure)
</li>
</ul>
  
<ul>
<li>
A Novel Cognitive Enhancement System. (Technology Disclosure)
</li>
</ul>
  
<h2>Projects</h2>
<ul>
<li>
Study Mental State Detection from Brain-Computer Interface System with EEG
</li>
</ul>
  
<ul>
<li>
Brain-Computer Interface-based Emotion Regulation for General Anxiety
</li>
</ul>
  
<ul>
<li>
NOURISH: Next-Generation Brain-Computer-Brain Platform – A Holistic Solution for the Restoration & Enhancement of Brain Functions
</li>
</ul>

<ul>
<li>
Attention-driven Car Racing Game with a Deep Learning Engine
</li>
</ul>
  
<h2>Acadamic service</h2>
<ul>
<li>
IEEE Transactions on Artificial Intelligence, reviewer
</li>
</ul>

<ul>
<li>
Cognitive Neurodynamics, reviewer
</li>
</ul>

<ul>
<li>
Neural Processing Letters, reviewer
</li>
</ul>

<h2>Teaching</h2>
<ul>
<li>
Mr. Ruyi An (NTU URECA 2021-2022)
</li>
</ul>

<ul>
<li>
Mr. Jethro Phuah An Ping (NTU FYP 2022-2023)
</li>
</ul>

<ul>
<li>
Mr. Kong Hou Jing (NTU FYP 2021-2022)
</li>
</ul>
  
<ul>
<li>
Miss. Gan Kah Ee (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Miss. Yuhan Zhang (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Mr. Nigel Wei Jun Ang (NTU FYP 2020-2021)
</li>
</ul>

</div>
</body>
</html>
