<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Welcom to Ding Yi's Homepage</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Ding Yi (‰∏Å‰∏ÄÔºâ</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://dyi1994.github.io/"><img src="myphoto.png" alt="alt text" width="180px" /></a>&nbsp;</td>
<td align="left"><p>Ph.D., MSc, B.Eng<br />
Research Assistant Professor<br />
College of Computing & Data Science<br />
Nanyang Technological University,<br />
Singapore<br /> 
Member, IEEE (CIS and EMBS), AAAI, and PREMIA <br />
Email: yi006@e.ntu.edu.sg/ding.yi@ntu.edu.sg <br />
<br />
<a href="https://www.researchgate.net/profile/Yi-Ding-113">[ResearchGate]</a> <a href="https://scholar.google.com/citations?user=8SYAgGIAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/yi-ding-cs">[GitHub]</a></p>
</td></tr></table>
<br />
<p style="color: #CD7F32;">‚ùóRecently someone is trying to impersonate me using unauthorized gmail. My official email accounts are <i><b>ding.yi@ntu.edu.sg</b></i> and <i><b>yi006@e.ntu.edu.sg</b></i>. Please be careful about any requests from other email accounts. </p>
<h2>Biography</h2>
<p> I am currently a Research Assitant Professor at College of Computing and Data Science, Nanyang Technological University (NTU), Singapore. I received my Ph.D. from the School of Computer Science and Engineering (SCSE) at Nanyang Technological University, Singapore in 2023, supervised by <a href="https://ntu-cbcr.org/">Prof Guan Cuntai</a>. 
Before that, I received my MSc from the School of Electrical and Electronics Engineering (EEE) at Nanyang Technological University, Singapore in 2018, supervised by <a href="https://dr.ntu.edu.sg/cris/rp/rp00292"> Prof Chen Tupei</a>. 
Previously, I earned my B.Eng degree from the School of Information Science and Technology at Donghua University, Shanghai, China in 2017.
<br /><br />
My research interests include brain-computer interfaces, deep/machine learning, affective computing, computational neuroscience, foundation model, multimodal emotion recognition,
and their applications in neural signal decoding and mental disorder regulation. 
<br /><br />
ü§ù Students and scholars in related research fields are welcome to collaborate üìß. 
  
<p style="color: #CD5C5C;">üéì I am looking for <b>one CSC-scholar</b> who is interested in BCI, Foundation Models, Mutimodal Emotion Recgnation. Please feel free to contact me if you are interested.</p>
</p>
 
<h2>News</h2>
<table class="imgtable">
  <tr><td>
    <ul>
      <li><p>[28-Jan-2026] 1 paper was accepted by <i><b>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</b></i>, thanks all co-authors</p></li>
      <li><p>[26-Jan-2026] 3 papers were accepted by <i><b>ICLR-2026</b></i>, thanks all co-authors</p></li>
      <li><p>[20-Nov-2025] 1 paper was accepted by <i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI)</b></i>, thanks all co-authors</p></li>
      <li><p>[8-Nov-2025] 1 paper was accepted by <i><b>AAAI-2026</b></i>, thanks all co-authors</p></li>
      <li><p>[19-Sep-2025] 1 paper was accepted by <i><b>NeurIPS-2025</b></i>, thanks all co-authors</p></li>
      <li><p>[16-Jul-2025] 1 paper was accepted by <i><b>IEEE Signal Processing Magazine (SPM)</b></i>, thanks all co-authors</p></li>
      <li><p>[5-Jul-2025] 1 paper was accepted by <i><b>ACM MM-25</b></i>, thanks all co-authors</p></li>
      <li><p>[3-Jul-2025] 1 paper was accepted by <i><b>Neural Networks (NN)</b></i>, thanks all co-authors</p></li>
      <li><p>[11-Apr-2025] 1 paper was accepted by <i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE)</b></i>, thanks all co-authors</p></li>
      <li><p>[8-Apr-2025] 1 paper was accepted by <i><b>EMBC-25</b></i>, thanks all co-authors</p></li>
      <li><p>[14-Mar-2025] 1 paper was accepted by <i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</b></i>, thanks all co-authors</p></li>
      <li><p>[24-Dec-2024] I was awarded as a <i><b>Research Assistant Professor</b></i> in NTU, thanks to my supervisor Prof Guan</p></li>
      <li><p>[21-Dec-2024] 2 papers were accepted by <i><b>ICASSP-25</b></i>, thanks all co-authors</p></li>
      <li><p>[16-Dec-2024] 1 paper was accepted by <i><b>IEEE Transactions on Image Processing (TIP)</b></i>, thanks all co-authors</p></li>
      <li><p>[16-Nov-2024] 2 papers were accepted by <i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI)</b></i>, thanks all co-authors</p></li>
      <li><p>[12-Nov-2024] 1 paper was accepted by <i><b>IEEE Transactions on Affective Computing (TAFFC)</b></i>, thanks all co-authors</p></li>
      <li><p>[17-Jun-2024] 1 paper was accepted by <i><b>Neural Networks (NN)</b></i>, thanks all co-authors</p></li>
      <li><p>[8-May-2024] 1 paper was accepted by <i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE)</b></i>, thanks all co-authors</p></li>
      <li><p>[16-Apr-2024] 1 paper was accepted by <i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI)</b></i>, thanks all co-authors</p></li>
      <li><p>[4-Jan-2024] 1 paper was accepted by <i><b>Neural Networks (NN)</b></i>, thanks all co-authors</p></li>
      <li><p>[31-Aug-2023] LGGNet was honored with <i><b>the PREMIA Best Student Paper Awards Honourable Mention 2023</b></i></p></li>
      <li><p>[12-Apr-2023] 2 papers were accepted by <i><b>EMBC-23</b></i></p></li>
      <li><p>[11-Jan-2023] 1 paper was accepted by <i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</b></i></p></li>
      <li><p>[25-Nov-2022] 1 PCT patent application (PCT/SG2022/050243), "Mental Arousal Level Regulation System and Method", was published</p></li>
      <li><p>[19-Aug-2022] My Ph.D. Thesis, "Neurophysiology-Inspired Neural Networks for Affective Brain-Computer Interfaces", was submitted and endorsed by Prof Guan</p></li>
      <li><p>[26-Apr-2022] 1 paper was accepted by <i><b>IJCNN-22</b></i></p></li>
      <li><p>[16-Apr-2022] 1 paper was accepted by <i><b>IEEE Transactions on Affective Computing (TAFFC)</b></i></p></li>
      <li><p>[15-Apr-2022] 1 paper was accepted by <i><b>CVPRW-22</b></i></p></li>
      <li><p>[15-Apr-2022] Our team achieved the runner-up in the Valence-arousal estimation challenge of ABAW Competition held in <i><b>CVPR-22</b></i></p></li>
    </ul>
  </td></tr>
</table>

<h2>Publications</h2>
  <h3>Journal Papers</h3>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10960695">EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion Recognition</a> <br />
<b>Yi Ding</b>, Chengxuan Tong, Shuailei Zhang, Muyun Jiang, Yong Li, Kevin Lim Jun Liang, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2025. </b></i>[JCR Q1, IF=10.4] <a href="https://ieeexplore.ieee.org/ielx8/5962385/6104215/10960695.pdf?tp=&arnumber=10960695&isnumber=6104215&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2RvY3VtZW50LzEwOTYwNjk1">[PDF]</a><a href="https://github.com/yi-ding-cs/EmT">[code]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10763464">EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces</a><br />
<b>Yi Ding</b>, Yong Li, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu, Xinliang Zhou, and Cuntai Guan<br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024 </b></i>[JCR Q1, IF=6.7]<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10763464">[PDF]</a><a href="https://github.com/yi-ding-cs/EEG-Deformer">[code]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10506986">MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition</a> <br />
<b>Yi Ding</b>, Su Zhang, Chuangao Tang, Cuntai Guan <br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024. </b></i>[JCR Q1, IF=7.7] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10506986">[PDF]</a><a href="https://github.com/yi-ding-cs/MASA-TCN">[code]</a> </p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10025569">LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Chengxuan Tong, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023. </b></i>[JCR Q1, IF=10.4] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10025569">[PDF]</a><a href="https://github.com/yi-ding-cs/LGG">[code]</a></p>
</li>
</ul>
  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9762054">TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition
</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Su Zhang, Qiuhao Zeng, Cuntai Guan <br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), 2022.</i></b>  [JCR Q1, IF=11.2] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9762054">[PDF]</a><a href="https://github.com/yi-ding-cs/TSception">[code]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2503.00580">Brain Foundation Models: A Survey on Advancements in Neural Signal Processing and Brain Discovery</a> <br />
Xinliang Zhou, Chenyu Liu, Zhisheng Chen, Kun Wang, <b>Yi Ding</b>, Ziyu Jia, Qingsong Wen<br />
<i><b>IEEE Signal Processing Magazine (SPM), 2025, Accepted </b></i>[JCR Q1, IF=9.6] <a href="https://arxiv.org/pdf/2503.00580">[PDF]</a>[Corresponding]</p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2504.03762">Decoding Covert Speech from EEG Using a Functional Areas Spatio-Temporal Transformer</a><br />
Muyun Jiang, Wei Zhang, <b>Yi Ding</b>, et. al. <br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2025, accepted </b></i>[JCR Q1, IF=6.7]</p>
</li>
</ul>


<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S0893608025006550?via%3Dihub">Decoding olfactory response from neurophysiological signal with a multi modal deep learning framework</a> <br />
Chengxuan Tong, <b>Yi Ding</b>, Aung Aung Phyo Wai, Hui Xin Joanna Chua, Xiaorong Wu, Kevin JunLiang Lim, Cuntai Guan <br />
<i><b>Neural Networks (NN), 2025. </b></i>[JCR Q1, IF=6.3] <a href="https://pdf.sciencedirectassets.com/271125/1-s2.0-S0893608025X00083/1-s2.0-S0893608025006550/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDEaCXVzLWVhc3QtMSJIMEYCIQDChS4cdtt2uG2fFyWCPLCw1UZRVIcEsZjrfeYpb738GwIhAKiiELzr84xRj8%2B%2Bd5JGyNMMg0czkEJvtOqJzmrUaidiKrMFCDoQBRoMMDU5MDAzNTQ2ODY1Igxyfr5mfWxfaWHYFWIqkAX19oE8p1ALvhWo2xy9zqKrs3Dfm46mhpFpxzgq%2B%2FsD08DFWWikQhY%2BCrfrn6ewKMRCUCbKa5e7jH%2FFI6rWqfnAwd17%2FCPWtSDpQghkRem0Q%2FcJDeaKPiP9TJOzndbEDI2wG0VW%2FyZTa1WXScfF8avwBQxcG1io%2F83AAt3xXd%2FMw8bbZOlaMT73Q232BhL873YQuMjI8Z2hFQwYdKpvHKUYXoPGNhndNzHVSkuNV1DbJJt8jfrNeEGAGmMbeYaqKegGugVcIDKjmQWnmV8pT5Gpy%2B0lP2jVAzkD2AIunPJ7x9WJuI%2F5BXGIG4JPt%2BM7KhyhLelWnZ3DFHAYO6mPI9pZT2ZMG9bL%2Bi30Xmut1QBjxTEeMQlsGRMCo7nLv0IYOl5UUquzo%2BPUx%2Fd3by9ZS%2FNW40x%2FaLhJj7z4C4%2Fs6RDpXWu951Za4giuFkeUgJmUhQOGiMCzqvmIoM%2BnZeqxB856j7WloAHXtyxHgPK6z0IP0Ni47c7%2F4AI11CZyONpHMGWssTsjYrOyEEsMReGocvSrtP2%2F32VOOpRXVWn%2BVryBJ1QBlVzDqopJB3jAR9oxfqW9FR%2FpQ3%2B70toW3vabskLNLicX80uPZeTPyQSCJCk2hsEWkWFaNJLLcEo0aleUQ2tF9%2F6X8FXw8Q64qnZWh5vv62r8s8Go2rtlM9D%2FVs%2BJb6yOCn5Gy031Pl9lPdJVGqJdxQFpaImBKGk2c7kc4gP8as4nBgX7GuQN6fqYb%2BoinNMTY8PkgJO0RAMiuDFkOHrk0UAfzTuU%2FE1OOfR008yOma%2FZ70gJnkYqjDQzwK1M0V2Ut5TuQnyllUGEUTZp%2FHHBQ9ASIM9XOMWJVQxoorA8mZlBPVM54uTO3mLpd2OjljDF46HDBjqwAQ3UM2k%2B6J01bbvyl1avp%2BYNijrgjGackm1epgBswHN8Yn%2FN1StdMIj%2FfgtiMoiHmL1m9hSyO2mWlCZM7rQqFwawRtTogAeqqQ6qpvxF55mHFr4TWmptgIqaaIcmyN82CI4ruqDFwUJqPYzFIXYUMwMslAlkIUQHOavnlongcyafxsRjeGJ3lROkslG9E9dWOGMRIzXyxFuhkw447qxlWUSwmhRQ%2BO24%2FQRNVJc0iOaS&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250705T010225Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYUBKXRO3K%2F20250705%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=f3c9a69cabd6a9e5ed7de1228d0971f47ec0fbbf0d6c62afe31b30549439dd73&hash=dc90ce4de1aca4a707305d83bec667c73c4c24d0ed21f2ec3c7ce2133a313220&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0893608025006550&tid=spdf-cc595d87-3185-4c27-a212-6558ebb377a9&sid=d0c2d0eb8e280243ce4bdc88791ad377e611gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=09015b5b0e56050100&rr=95a2efcf8bc8fce3&cc=sg">[PDF]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10964365">SRRNet: Unseen SSVEP Response Regression From Stimulus for Cross-Stimulus Transfer in SSVEP-BCIs</a> <br />
Ximing Mai, Jianjun Meng, <b>Yi Ding</b>, Xiangyang Zhu, Cuntai Guan<br />
<i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE), 2025. </b></i>[JCR Q1, IF=5.2] <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10964365">[PDF]</a><a href="https://github.com/MaiXiming/SRRNet">[Code]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10914502">Decoupled Doubly Contrastive Learning for Cross Domain Facial Action Unit Detection</a><br />
Yong Li, Menglin Liu, Zhen Cui, <b>Yi Ding</b>, Yuan Zong, Wenming Zheng, Shiguang Shan, and Cuntai Guan<br />
<i><b>IEEE Transactions on Image Processing (TIP), 2025. </b></i>[JCR Q1, IF=10.8]</p>
</li>
</ul>
  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10904329">Beyond Overfitting: Doubly Adaptive Dropout for Generalizable AU Detection</a><br />
Yong Li, Yi Ren, Xuesong Niu, <b>Yi Ding</b>, Xiu-Shen Wei, and Cuntai Guan<br />
<i><b>IEEE Transactions on Affective Computing (TAFFC), 2025 </b></i>[JCR Q1, IF=9.6]</p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10758636">REI-Net: A Reference Electrode Standardization Interpolation Technique based 3D CNN for Motor Imagery Classification</a><br />
Meiyan Xu, Jie Jiao, Duo Chen, <b>Yi Ding</b>, et. al. <br />
<i><b>IEEE Journal of Biomedical and Health Informatics (J-BHI), 2024. </b></i>[JCR Q1, IF=6.7]</p>
</li>
</ul>

<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024003940?via%3Dihub">Leveraging Temporal Dependency for Cross-subject-MI BCIs by Contrastive Learning and Self-attention</a><br />
Hao Sun, <b>Yi Ding</b>, Jianzhu Bao, Chengxuan Tong, Jing Jin, Cuntai Guan <br />
<i><b>Neural Networks (NN), 2024. </b></i>[JCR Q1, IF=7.8]</p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10528328">TASA: Temporal Attention with Spatial Autoencoder Network for Odor-induced Emotion Classification Using EEG</a> <br />
Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, Zhuo Zhang, Haihong Zhang, Cuntai Guan <br />
<i><b>IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE), 2024. </b></i>[JCR Q1, IF=4.9]</p>
</li>
</ul>

<ul>
<li><p><a href="https://arxiv.org/abs/2308.11636"> Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning</a> <br />
Rui Liu, Yuanyuan Chen, Anran Li, <b>Yi Ding </b>, Han Yu, Cuntai Guan <br />
<i><b> Neural Networks(NN), 2024. </b></i>[JCR Q1, IF=7.8]<a href="https://arxiv.org/pdf/2308.11636.pdf">[PDF]</a><a href="https://github.com/RuiLiu-cc/FLEEG">[code]</a></p>
</li>
</ul>

<h3>Conference Papers</h3>

<ul>
<li><p> <a href="https://arxiv.org/abs/2509.22556"> ECHO: Toward Contextual Seq2Seq Paradigms in Large EEG Models </a><br />
Chenyu Liu, Yuqiu Deng, Tianyu Liu, Jinan Zhou, Xinliang Zhou, Ziyu Jia, <b>Yi Ding</b><br />
<i><b>The Fourteenth International Conference on Learning Representations (ICLR), 2026.</b></i><a href="https://arxiv.org/pdf/2509.22556?">[PDF]</a>[Corresponding]</p>
</li>
</ul>

<ul>
<li><p> <a href="https://arxiv.org/abs/2512.12210"> EEG-DLite: Dataset Distillation for Efficient Large EEG Model Training </a><br />
Yuting Tang, Weibang Jiang, Shanglin Li, Yong Li, Chenyu Liu, Xinliang Zhou, <b>Yi Ding</b>, Cuntai Guan, <br />
<i><b>The Fortieth AAAI Conference on Artificial Intelligence (AAAI), 2026.</b></i><a href="https://arxiv.org/pdf/2512.12210">[PDF]</a><a href="https://github.com/t170815518/EEG-DLite">[code]</a> [Corresponding]</p>
</li>
</ul>
  
<ul>
<li><p><a href="https://dl.acm.org/doi/10.1145/3746027.3754775"> Sera: Separated Coarse-to-fine Representation Alignment for Cross-subject EEG-based Emotion Recognition </a> <br />
Zhihao Jia, Meiyan Xu, Jing Yuan Wang, Ziyu Jia, Yong Li, Xinliang Zhou, Chenyu Liu, Junfeng Yao, <b>Yi Ding</b>, <br />
<i><b>ACM Multimedia (MM) 2025.</b></i> [Corresponding]</p>
</li>
</ul>

<ul>
<li><p> <a href="https://arxiv.org/abs/2502.03736">Decoding Human Attentive States from Spatial-temporal EEG Patches Using Transformers </a> <br />
<b>Yi Ding</b>, Joon Hei Lee, Shuailei Zhang, Tianze Luo, Cuntai Guan, <br />
<i><b>47rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2025.</b></i> <a href="https://arxiv.org/abs/2502.03736">[PDF]</a><a href="https://github.com/yi-ding-cs/EEG-PatchFormer">[code]</a></p>
</li>
</ul>

<ul>
<li><p> <a href="https://ieeexplore.ieee.org/document/10888948">SelectiveFinetuning: Enhancing Transfer Learning In Sleep Staging Through Selective Domain Alignment </a> <br />
Siyuan Zhao, Chenyu Liu, <b>Yi Ding</b>, and Xinliang Zhou <br />
<i><b>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2025.</b></i> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10888948">[PDF]</a>[Corresponding]</p>
</li>
</ul>

<ul>
<li><p> <a href="https://ieeexplore.ieee.org/abstract/document/10340644">GIGN: Learning Graph-in-graph Representations of EEG Signals for Continuous Emotion Recognition </a> <br />
<b>Yi Ding</b>, and Cuntai Guan <br />
<i><b>45rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2023.</b></i> <a href="https://github.com/yi-ding-cs/GIGN">[code] </a> </p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9629575"> Learning Generalized Representations of EEG between Multiple Cognitive Attention Tasks</a> <br />
<b>Yi Ding</b>, Nigel Wei Jun Ang, Aung Aung Phyo Wai, Cuntai Guan <br />
<i><b>43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2021. </b></i> <a href="https://paperhost.org/proceedings/embs/EMBC21/files/0591.pdf">[PDF]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/html/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.html">Continuous Emotion Recognition With Audio-Visual Leader-Follower Attentive Fusion</a> <br />
Su Zhang, <b>Yi Ding</b>, Ziquan Wei, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2021. </b></i> <a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_With_Audio-Visual_Leader-Follower_Attentive_Fusion_ICCVW_2021_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW2">[code]</a> [Equal contribution]</p>
</li>
</ul>

<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/9206750">TSception:A Deep Learning Framework for Emotion Detection Using EEG</a> <br />
<b>Yi Ding</b>, Neethu Robinson, Qiuhao Zeng, Duo Chen, Aung Aung Phyo Wai, Tih-Shih Lee, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2020. </b></i> <a href="https://arxiv.org/pdf/2004.02965.pdf"> [PDF]</a><a href="https://github.com/deepBrains/TSception">[code]</a></p>
</li>
</ul>

<ul>
<li><p> <a href="https://arxiv.org/abs/2509.24222"> Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning </a><br />
Zhisheng Chen, Yingwei Zhang, Qizhen Lan, Tianyu Liu, Huacan Wang, <b>Yi Ding</b>, Ziyu Jia, Ronghao Chen, Kun Wang, Xinliang Zhou <br />
<i><b>The Fourteenth International Conference on Learning Representations (ICLR), 2026.</b></i><a href="https://arxiv.org/pdf/2509.24222">[PDF]</a></p>
</li>
</ul>

<ul>
<li><p> <a href="https://arxiv.org/abs/2601.03322"> HEEGNet: Hyperbolic Embeddings for EEG </a><br />
Shanglin Li, Shiwen Chu, Okan Ko√ß, <b>Yi Ding</b>, Qibin Zhao, Motoaki Kawanabe, Ziheng Chen, <br />
<i><b>The Fourteenth International Conference on Learning Representations (ICLR), 2026.</b></i><a href="https://arxiv.org/pdf/2601.03322">[PDF]</a></p>
</li>
</ul>

<ul>
<li><p><a href="https://openreview.net/forum?id=C4IqLzavel&referrer=%5Bthe%20profile%20of%20Youfang%20Lin%5D(%2Fprofile%3Fid%3D~Youfang_Lin1)"> REFED: A Subject Real-time Dynamic Labeled EEG-fNIRS Synchronized Recorded Emotion Dataset</a> <br />
Xiaojun Ning, Jing Wang, Zhiyang Feng, Tianzuo Xin, Shuo Zhang, Shaoqi Zhang, Zheng Lian, <b>Yi Ding</b>, Youfang Lin, Ziyu Jia <br />
<i><b>The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS) 2025.</b></i></p>
</li>
</ul>

<ul>
<li><p> <a href="https://ieeexplore.ieee.org/document/10889107">CAT-Net: A Co-Adaptive Transfer Learning Network for BCI-Assisted Neurorehabilitation </a> <br />
Shuailei Zhang, <b>Yi Ding</b>, Muyun Jiang, Ning Tang, Effie Chew, Kai Keng Ang, and Cuntai Guan <br />
<i><b>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2025.</b></i> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10889107">[PDF]</p>
</li>
</ul>
  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/10340760">MTDN: Learning Multiple Temporal Dynamics Representation for Emotional Valence Classification with EEG </a><br />
Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, and Cuntai Guan <br />
<i><b>45rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), 2023. </b></i> </p>
</li>
</ul>
 
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9892920"> TESANet: Self-attention network for olfactory EEG classification </a><br />
Chengxuan Tong, <b>Yi Ding</b>, Kevin Lim Jun Liang, Zhuo Zhang, Haihong Zhang, Cuntai Guan<br />
<i><b>International Joint Conference on Neural Networks (IJCNN) 2022. </b></i> </p>
</li>
</ul>

<ul>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/html/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.html">Continuous Emotion Recognition Using Visual-Audio-Linguistic Information: A Technical Report for ABAW3</a> <br />
Su Zhang, Ruyi An, <b>Yi Ding</b>, Cuntai Guan <br />
<i><b>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. </b></i> <a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Zhang_Continuous_Emotion_Recognition_Using_Visual-Audio-Linguistic_Information_A_Technical_Report_for_CVPRW_2022_paper.pdf">[PDF]</a><a href="https://github.com/sucv/ABAW3">[code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/8717063">Motor-Controlled Spindle (MCS) Detection for Primate in BCI System</a> <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br /> <i><b>International IEEE/EMBS Conference on Neural Engineering (NER), 2019. </b></i></p>
</li>
</ul>
<ul>
<li><p>Intracortical Activity decoding of motor imagery based on Deep Convolutional Neural Network: a Pilot Study. <br />
Duo Chen, Rosa So, <b>Yi Ding</b>, Cuntai Guan<br /><i><b>GBCIC, 2019. </b></i></p>
</li>
</ul>
<h2>Patents and TDs</h2>
<ul>
<li>
Mental Arousal Level Regulation System and Method (PCT/SG2022/050243 & 202280034110.2)
</li>
</ul>

<ul>
<li>
Music-based Emotion Profiling System. (PCT/SG2023/050757)
</li>
</ul>
  
<ul>
<li>
System and Method for Cognitive Enhancement Based on Electroencephalogram(EEG) Signals. (PCT/SG2023/050758)
</li>
</ul>

<ul>
<li>
Foundation Model for EEG Continuous Decoding (TD)
</li>
</ul>

<ul>
<li>
Data-Efficient Training Method for EEG Models (TD)
</li>
</ul>

<ul>
<li>
Calibration-Free Brain-Computer Interface System (TD)
</li>
</ul>

<ul>
<li>
BCI with Perception-Consistent Feedback (TD)
</li>
</ul>

<ul>
<li>
BCI-driven Integrated Motor and Attention Training (BCI-iMAT) System (TD)
</li>
</ul>

<ul>
<li>
Agentic Multimodal Emotion Recognition System (TD)
</li>
</ul>

<ul>
<li>
EEG Emotion Tagging System (TD)
</li>
</ul>
  
<h2>Projects</h2>

<ul>
<li>
Effective Emotion Recognition from Neurophysiological Signals
</li>
</ul>

<ul>
<li>
Brain-Computer Interface-based Emotion Regulation for General Anxiety
</li>
</ul>
  
<ul>
<li>
Technology Transfer of EEG-Based Anxiety Regulation System to Mental Health Startup
</li>
</ul>

<ul>
<li>
NOURISH: Next-Generation Brain-Computer-Brain Platform ‚Äì A Holistic Solution for the Restoration & Enhancement of Brain Functions
</li>
</ul>

<ul>
<li>
Scent Digitalization and Computation (SDC), Collaboration with MSE
</li>
</ul>

<ul>
<li>
Study Mental State Detection from Brain-Computer Interface System with EEG
</li>
</ul>
  
<h2>Acadamic service</h2>
  
<ul>
<li>
IEEE Transactions on Neural Networks and Learning Systems, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Systems, Man, and Cybernetics: Systems, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Affective Computing, reviewer
</li>
</ul>

<ul>
<li>
IEEE Reviews in Biomedical Engineering, reviewer
</li>
</ul>

<ul>
<li>
IEEE Internet of Things Journal, reviewer
</li>
</ul>

<ul>
<li>
IEEE Journal of Biomedical and Health Informatics, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Signal Processing, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Neural Systems and Rehabilitation Engineering, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Cognitive and Developmental Systems, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Artificial Intelligence, reviewer
</li>
</ul>

<ul>
<li>
IEEE Transactions on Human-Machine Systems, reviewer
</li>
</ul>

<ul>
<li>
Information Fusion, reviewer
</li>
</ul>

<ul>
<li>
Pattern Recognition, reviewer
</li>
</ul>

<ul>
<li>
Information Sciences, reviewer
</li>
</ul>

<ul>
<li>
Applied Soft Computing, reviewer
</li>
</ul>

<ul>
<li>
International Journal of Human-Computer Interaction, reviewer
</li>
</ul>

<ul>
<li>
Neurocomputing, reviewer
</li>
</ul>

<ul>
<li>
Cognitive Neurodynamics, reviewer
</li>
</ul>

<ul>
<li>
Neural Processing Letters, reviewer
</li>
</ul>
  
<ul>
<li>
Applied Artificial Intelligence, reviewer
</li>
</ul>

<ul>
<li>
Brain Research Bulletin, reviewer
</li>
</ul>

<ul>
<li>
Reviewer/PC: ICASSP-25, IJCNN-25, EMBC-25, ACM MM-25, AAAI-26, ICLR-26, ICASSP-26, CVPR-2026, ICML-2026
</li>
</ul>

<ul>
<li>
AE: IEEE SMC-2026
</li>
</ul>

<ul>
<li>
Co-session Chair: AAAI-2026 (Human-AI Interaction)
</li>
</ul>

<ul>
<li>
Guest Editor: Frontiers in Medicine (Aritificial Intelligence for Aging and Age-Related Healthcare: Diagnosis, Prediction, and Personalized Care)
</li>
</ul>


<ul>
<li>
Brain-X, Young editorial board
</li>
</ul>

<h2>Teaching</h2>

Postgraduates 
<ul>
<li>
Ms. Chen Jingyuan (MSc & PhD, NTU)
</li>
</ul> 

<ul>
<li>
Dr. Tong Chengxuan (PhD, NTU) Graduated
</li>
</ul> 

<ul>
<li>
Mr. Jia Zhihao (PhD, XMU)
</li>
</ul>

<ul>
<li>
Ms. Wang Jingyuan (PhD, XMU)
</li>
</ul>

<ul>
<li>
Mr. Peng Hao (PhD, XMU)
</li>
</ul>

<ul>
<li>
Ms. Tang Yuting (Project Officer, NTU)
</li>
</ul>

Undergraduates
<ul>
<li>
Mr. Zhou Runhe (Undergraduate, NTU)
</li>
</ul>

<ul>
<li>
Mr. Isaac Hong Zhang Jie (FYP 2024-2025, NTU)
</li>
</ul>
  
<ul>
<li>
Mr. Ruyi An (NTU URECA 2021-2023, and FYP 2023-2024)
</li>
</ul>

<ul>
<li>
Mr. Lee Joonhei (NTU FYP 2023-2024)
</li>
</ul>

<ul>
<li>
Mr. Jethro Phuah An Ping (NTU FYP 2022-2023)
</li>
</ul>

<ul>
<li>
Mr. Kong Hou Jing (NTU FYP 2021-2022)
</li>
</ul>
  
<ul>
<li>
Miss. Gan Kah Ee (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Miss. Yuhan Zhang (NTU URECA 2020-2021)
</li>
</ul>

<ul>
<li>
Mr. Nigel Wei Jun Ang (NTU FYP 2020-2021)
</li>
</ul>

</div>
</body>
</html>
